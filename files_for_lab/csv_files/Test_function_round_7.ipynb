{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cfc71f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round2_cleaning(input_data):\n",
    "    \n",
    "    # create a copy of the original dataset, to avoid changing the raw data\n",
    "    output_data = input_data.copy()\n",
    "\n",
    "    # harmonize feaders\n",
    "    output_data = output_data.rename(columns={'EmploymentStatus': 'Employment Status'})\n",
    "    \n",
    "    # delete useless data\n",
    "    output_data = output_data.drop(['Unnamed: 0', 'Vehicle Type'], axis=1)\n",
    "    output_data = output_data.dropna()\n",
    "    \n",
    "    # change format of the date and add the extra column with the month\n",
    "    output_data['Effective To Date'] = pd.to_datetime(output_data['Effective To Date'], errors='coerce')\n",
    "    output_data['Effective To Month'] = output_data['Effective To Date'].apply(lambda x: x.month)\n",
    "    \n",
    "    # filter the data\n",
    "    output_data = output_data[output_data['Effective To Month'] <=3 ]\n",
    "    \n",
    "    # output of the function\n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16865ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def round7_modeling(input_data):\n",
    "    \n",
    "#     # We start by cleaning the data, calling the function created at the end of Round 2\n",
    "#     cleaned_input = round2_cleaning(input_data)\n",
    "    \n",
    "#     # Data processing\n",
    "#     import pandas as pd\n",
    "#     import numpy as np\n",
    "#     # Split numerical from categoricals\n",
    "#     numericals = cleaned_input._get_numeric_data()\n",
    "#     categoricals = cleaned_input.select_dtypes(['object']).drop(['Customer'], axis=1)\n",
    "    \n",
    "#     # Define target and features\n",
    "#     y = cleaned_input['Total Claim Amount']\n",
    "#     X = numericals.drop(['Total Claim Amount'], axis = 1)\n",
    "    \n",
    "#     # Standardize the features\n",
    "#     from sklearn.preprocessing import StandardScaler\n",
    "#     transformer = StandardScaler().fit(X)\n",
    "#     X_standardized = transformer.transform(X)\n",
    "#     X_standardized = pd.DataFrame(X_standardized, columns=X.columns)\n",
    "    \n",
    "#     # Standardize the categoricals\n",
    "#     from sklearn.preprocessing import OneHotEncoder\n",
    "#     cat_onehot = categoricals[['State', 'Response', 'Employment Status', 'Gender', 'Location Code', 'Marital Status', 'Policy Type', 'Policy', 'Sales Channel', 'Vehicle Class']].copy()\n",
    "#     encoder = OneHotEncoder().fit(cat_onehot)\n",
    "#     cols = [colname for row in encoder.categories_ for colname in row]\n",
    "#     encoded = encoder.transform(cat_onehot).toarray()\n",
    "#     cat_onehot_encoded = pd.DataFrame(encoded,columns=cols)\n",
    "#     cols_to_drop = [row[0] for row in encoder.categories_]\n",
    "#     cat_onehot_encoded = cat_onehot_encoded.drop(cols_to_drop, axis=1)\n",
    "    \n",
    "#     cat_label = categoricals[['Coverage', 'Renew Offer Type', 'Education', 'Vehicle Size']].copy()\n",
    "#     coverage_mapper = { 'Basic':1, 'Extended':2, 'Premium':3 }\n",
    "#     education_mapper = { 'High School or Below':1, 'College':2, 'Bachelor':3, 'Master':4, 'Doctor':5 }\n",
    "#     veh_size_mapper = { 'Small':1, 'Medsize':2, 'Large':3 }\n",
    "\n",
    "#     cat_label['Coverage'] = cat_label['Coverage'].replace(coverage_mapper)\n",
    "#     cat_label['Education'] = cat_label['Education'].replace(education_mapper)\n",
    "#     cat_label['Vehicle Size'] = cat_label['Vehicle Size'].replace(veh_size_mapper)\n",
    "#     cat_label['Renew Offer Type'] = cat_label['Renew Offer Type'].str[-1:]\n",
    "#     categoricals_encoded = pd.concat([cat_onehot_encoded, cat_label], axis=1)\n",
    "#     X_complete = pd.concat([X_standardized, categoricals_encoded], axis=1)\n",
    "    \n",
    "#     # Linear regression\n",
    "#     from sklearn.model_selection import train_test_split\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X_complete, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "#     from sklearn import linear_model\n",
    "#     lm = linear_model.LinearRegression()\n",
    "#     lm.fit(X_train,y_train)\n",
    "    \n",
    "    \n",
    "#     from sklearn.metrics import r2_score\n",
    "#     predictions_train = lm.predict(X_train)\n",
    "#     R2_train = r2_score(y_train, predictions_train)\n",
    "#     predictions_test = lm.predict(X_test)\n",
    "#     R2_test = r2_score(y_test, predictions_test)\n",
    "#     from sklearn.metrics import mean_squared_error\n",
    "#     mse_train = np.sqrt(mean_squared_error(y_train,predictions_train))\n",
    "#     mse_test = np.sqrt(mean_squared_error(y_test,predictions_test))\n",
    "    \n",
    "#     import math\n",
    "#     rmse_train = math.sqrt(mse_train)\n",
    "#     rmse_test = math.sqrt(mse_test)\n",
    "    \n",
    "#     from sklearn.metrics import mean_absolute_error\n",
    "#     mae_train = mean_absolute_error(y_train, predictions_train)\n",
    "#     mae_test = mean_absolute_error(y_test, predictions_test)\n",
    "    \n",
    "#     validation_matrix = { 'Indicator':['R2','mse', 'rmse', 'mae'],\n",
    "#                  'Train Set': [R2_train, mse_train, rmse_train, mae_train],\n",
    "#                  'Test Set': [R2_test, mse_test, rmse_test, mae_test]\n",
    "#                 } \n",
    "    \n",
    "#     return validation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce963497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "input_data = pd.read_csv('marketing_customer_analysis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d42e8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_matrix = round7_modeling(data)\n",
    "# output_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5b2cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# We start by cleaning the data, calling the function created at the end of Round 2\n",
    "cleaned_input = round2_cleaning(input_data)\n",
    "    \n",
    "# Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "    # Exclude outliers from the data set for \"Customer Lifetime Value\" and \"Monthly Premium Auto\"\n",
    "iqr_lifetime = np.percentile(cleaned_input['Customer Lifetime Value'],75) - np.percentile(cleaned_input['Customer Lifetime Value'],25)\n",
    "upper_limit_lifetime = np.percentile(cleaned_input['Customer Lifetime Value'],75) + 1.5*iqr_lifetime\n",
    "lower_limit_lifetime = np.percentile(cleaned_input['Customer Lifetime Value'],25) - 1.5*iqr_lifetime\n",
    "cleaned_input = cleaned_input[(cleaned_input['Customer Lifetime Value']>lower_limit_lifetime) & (cleaned_input['Customer Lifetime Value']<upper_limit_lifetime)]\n",
    "\n",
    "iqr_premium = np.percentile(cleaned_input['Monthly Premium Auto'],75) - np.percentile(cleaned_input['Monthly Premium Auto'],25)\n",
    "upper_limit_premium = np.percentile(cleaned_input['Monthly Premium Auto'],75) + 1.5*iqr_premium\n",
    "lower_limit_premium = np.percentile(cleaned_input['Monthly Premium Auto'],25) - 1.5*iqr_premium\n",
    "cleaned_input = cleaned_input[(cleaned_input['Monthly Premium Auto']>lower_limit_premium) & (cleaned_input['Monthly Premium Auto']<upper_limit_premium)]  \n",
    "\n",
    "sns.displot(cleaned_input['Customer Lifetime Value'])\n",
    "plt.show()\n",
    "sns.displot(cleaned_input['Monthly Premium Auto'])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Split numerical from categoricals\n",
    "numericals = cleaned_input._get_numeric_data()\n",
    "categoricals = cleaned_input.select_dtypes(['object']).drop(['Customer'], axis=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Define target and features\n",
    "y = cleaned_input['Total Claim Amount']\n",
    "X = numericals.drop(['Total Claim Amount'], axis = 1)\n",
    "    \n",
    "    # Standardize the features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "transformer = StandardScaler().fit(X)\n",
    "X_standardized = transformer.transform(X)\n",
    "X_standardized = pd.DataFrame(X_standardized, columns=X.columns)\n",
    "    \n",
    "     # Standardize the categoricals\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "cat_onehot = categoricals[['State', 'Response', 'Employment Status', 'Gender', 'Location Code', 'Marital Status', 'Policy Type', 'Policy', 'Sales Channel', 'Vehicle Class']].copy()\n",
    "cat_onehot.reset_index(drop=True)\n",
    "encoder = OneHotEncoder().fit(cat_onehot)\n",
    "cols = [colname for row in encoder.categories_ for colname in row]\n",
    "encoded = encoder.transform(cat_onehot).toarray()\n",
    "cat_onehot_encoded = pd.DataFrame(encoded,columns=cols)\n",
    "cols_to_drop = [row[0] for row in encoder.categories_]\n",
    "cat_onehot_encoded = cat_onehot_encoded.drop(cols_to_drop, axis=1)\n",
    "    \n",
    "cat_label = categoricals[['Coverage', 'Renew Offer Type', 'Education', 'Vehicle Size']].copy()\n",
    "coverage_mapper = { 'Basic':1, 'Extended':2, 'Premium':3 }\n",
    "education_mapper = { 'High School or Below':1, 'College':2, 'Bachelor':3, 'Master':4, 'Doctor':5 }\n",
    "veh_size_mapper = { 'Small':1, 'Medsize':2, 'Large':3 }\n",
    "\n",
    "cat_label['Coverage'] = cat_label['Coverage'].replace(coverage_mapper)\n",
    "cat_label['Education'] = cat_label['Education'].replace(education_mapper)\n",
    "cat_label['Vehicle Size'] = cat_label['Vehicle Size'].replace(veh_size_mapper)\n",
    "cat_label['Renew Offer Type'] = cat_label['Renew Offer Type'].str[-1:]\n",
    "cat_label.reset_index(drop=True, inplace=True)\n",
    "cat_onehot_encoded.reset_index(drop=True, inplace=True)\n",
    "categoricals_encoded = pd.concat([cat_onehot_encoded, cat_label], axis=1)\n",
    "X_complete = pd.concat([X_standardized, categoricals_encoded], axis=1)\n",
    "\n",
    "    \n",
    "# Linear regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_complete, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "from sklearn import linear_model\n",
    "lm = linear_model.LinearRegression()\n",
    "lm.fit(X_train,y_train)\n",
    "    \n",
    "    \n",
    "from sklearn.metrics import r2_score\n",
    "predictions_train = lm.predict(X_train)\n",
    "R2_train = r2_score(y_train, predictions_train)\n",
    "predictions_test = lm.predict(X_test)\n",
    "R2_test = r2_score(y_test, predictions_test)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse_train = np.sqrt(mean_squared_error(y_train,predictions_train))\n",
    "mse_test = np.sqrt(mean_squared_error(y_test,predictions_test))\n",
    "    \n",
    "import math\n",
    "rmse_train = math.sqrt(mse_train)\n",
    "rmse_test = math.sqrt(mse_test)\n",
    "    \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae_train = mean_absolute_error(y_train, predictions_train)\n",
    "mae_test = mean_absolute_error(y_test, predictions_test)\n",
    "    \n",
    "# validation_matrix = { 'Indicator':['R2','mse', 'rmse', 'mae'],\n",
    "#              'Train Set': [R2_train, mse_train, rmse_train, mae_train],\n",
    "#              'Test Set': [R2_test, mse_test, rmse_test, mae_test]\n",
    "#             } \n",
    "\n",
    "# validation_matrix = pd.DataFrame(validation_matrix)\n",
    "\n",
    "validation_matrix = { 'Train Set': [R2_train, mse_train, rmse_train, mae_train],\n",
    "                 'Test Set': [R2_test, mse_test, rmse_test, mae_test]\n",
    "                } \n",
    "validation_matrix = pd.DataFrame(validation_matrix, index=['R2','mse', 'rmse', 'mae'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2fc9a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b416fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea2fabe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2312c988",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_data = pd.read_csv('marketing_customer_analysis.csv')\n",
    "\n",
    "sns.displot(control_data['Customer Lifetime Value'])\n",
    "plt.show()\n",
    "sns.displot(control_data['Monthly Premium Auto'])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "470ae6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "input_data = pd.read_csv('marketing_customer_analysis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0614624b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Customer Lifetime Value', 'Income', 'Monthly Premium Auto',\n",
      "       'Months Since Last Claim', 'Months Since Policy Inception',\n",
      "       'Number of Open Complaints', 'Number of Policies', 'Total Claim Amount',\n",
      "       'Effective To Month'],\n",
      "      dtype='object')\n",
      "0     4809.216960\n",
      "1     2228.525238\n",
      "2    14947.917300\n",
      "3    22332.439460\n",
      "6     5035.035257\n",
      "Name: Customer Lifetime Value, dtype: float64\n",
      "73117126.298532\n",
      "0    48029\n",
      "1        0\n",
      "2    22139\n",
      "6    37405\n",
      "7    87197\n",
      "Name: Income, dtype: int64\n",
      "313039212\n",
      "0     61\n",
      "1     64\n",
      "2    100\n",
      "6     63\n",
      "7     63\n",
      "Name: Monthly Premium Auto, dtype: int64\n",
      "756428\n",
      "0     7.0\n",
      "1     3.0\n",
      "2    34.0\n",
      "6     8.0\n",
      "7    35.0\n",
      "Name: Months Since Last Claim, dtype: float64\n",
      "120424.0\n",
      "0    52\n",
      "1    26\n",
      "2    31\n",
      "6    99\n",
      "7    45\n",
      "Name: Months Since Policy Inception, dtype: int64\n",
      "384573\n",
      "0    0.0\n",
      "1    0.0\n",
      "2    0.0\n",
      "6    3.0\n",
      "7    0.0\n",
      "Name: Number of Open Complaints, dtype: float64\n",
      "3134.0\n",
      "Series([], Name: Number of Policies, dtype: int64)\n",
      "0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "cannot do a non-empty take from an empty axes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21652/4125487492.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleaned_input\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleaned_input\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0miqr_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpercentile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleaned_input\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m75\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpercentile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleaned_input\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mupper_limit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpercentile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleaned_input\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m75\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1.5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0miqr_col\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mlower_limit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpercentile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleaned_input\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1.5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0miqr_col\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mpercentile\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mpercentile\u001b[1;34m(a, q, axis, out, overwrite_input, interpolation, keepdims)\u001b[0m\n\u001b[0;32m   3816\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_quantile_is_valid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3817\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Percentiles must be in the range [0, 100]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3818\u001b[1;33m     return _quantile_unchecked(\n\u001b[0m\u001b[0;32m   3819\u001b[0m         a, q, axis, out, overwrite_input, interpolation, keepdims)\n\u001b[0;32m   3820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36m_quantile_unchecked\u001b[1;34m(a, q, axis, out, overwrite_input, interpolation, keepdims)\u001b[0m\n\u001b[0;32m   3935\u001b[0m                         interpolation='linear', keepdims=False):\n\u001b[0;32m   3936\u001b[0m     \u001b[1;34m\"\"\"Assumes that q is in [0, 1], and is an ndarray\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3937\u001b[1;33m     r, k = _ureduce(a, func=_quantile_ureduce_func, q=q, axis=axis, out=out,\n\u001b[0m\u001b[0;32m   3938\u001b[0m                     \u001b[0moverwrite_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverwrite_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3939\u001b[0m                     interpolation=interpolation)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36m_ureduce\u001b[1;34m(a, func, **kwargs)\u001b[0m\n\u001b[0;32m   3513\u001b[0m         \u001b[0mkeepdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3515\u001b[1;33m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3516\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36m_quantile_ureduce_func\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   4059\u001b[0m         \u001b[0mweights_above\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnot_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mindices_below\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4060\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4061\u001b[1;33m         \u001b[0mx_below\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0map\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices_below\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4062\u001b[0m         \u001b[0mx_above\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0map\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices_above\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4063\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mtake\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(a, indices, axis, out, mode)\u001b[0m\n\u001b[0;32m    189\u001b[0m            [5, 7]])\n\u001b[0;32m    190\u001b[0m     \"\"\"\n\u001b[1;32m--> 191\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'take'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: cannot do a non-empty take from an empty axes."
     ]
    }
   ],
   "source": [
    "\n",
    "    # We start by cleaning the data, calling the function created at the end of Round 2\n",
    "cleaned_input = round2_cleaning(input_data)\n",
    "    \n",
    "    # Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "    \n",
    "    # Exclude outliers from the data set for \"Customer Lifetime Value\" and \"Monthly Premium Auto\"\n",
    "numericals = cleaned_input._get_numeric_data()\n",
    "\n",
    "print(numericals.columns)\n",
    "\n",
    "for col in numericals.columns:\n",
    "        print(cleaned_input[col].head())\n",
    "        print(cleaned_input[col].sum())\n",
    "        iqr_col = np.percentile(cleaned_input[col], 75) - np.percentile(cleaned_input[col], 25)\n",
    "        upper_limit = np.percentile(cleaned_input[col], 75) + 1.5 * iqr_col\n",
    "        lower_limit = np.percentile(cleaned_input[col], 25) - 1.5 * iqr_col\n",
    "        cleaned_input = cleaned_input[(cleaned_input[col]>lower_limit)&(cleaned_input[col]<upper_limit)]\n",
    "    \n",
    "    # iqr_lifetime = np.percentile(cleaned_input['Customer Lifetime Value'],75) - np.percentile(cleaned_input['Customer Lifetime Value'],25)\n",
    "# upper_limit_lifetime = np.percentile(cleaned_input['Customer Lifetime Value'],75) + 1.5*iqr_lifetime\n",
    "# lower_limit_lifetime = np.percentile(cleaned_input['Customer Lifetime Value'],25) - 1.5*iqr_lifetime\n",
    "# cleaned_input = cleaned_input[(cleaned_input['Customer Lifetime Value']>lower_limit_lifetime) & (cleaned_input['Customer Lifetime Value']<upper_limit_lifetime)]\n",
    "\n",
    "# iqr_premium = np.percentile(cleaned_input['Monthly Premium Auto'],75) - np.percentile(cleaned_input['Monthly Premium Auto'],25)\n",
    "# upper_limit_premium = np.percentile(cleaned_input['Monthly Premium Auto'],75) + 1.5*iqr_premium\n",
    "# lower_limit_premium = np.percentile(cleaned_input['Monthly Premium Auto'],75) - 1.5*iqr_premium    \n",
    "# cleaned_input = cleaned_input[(cleaned_input['Monthly Premium Auto']>lower_limit_premium) & (cleaned_input['Monthly Premium Auto']<upper_limit_premium)]  \n",
    "\n",
    "cleaned_input = cleaned_input.reset_index(drop=True, inplace=False)\n",
    "    \n",
    "    # Split numerical from categoricals\n",
    "numericals = cleaned_input._get_numeric_data()\n",
    "categoricals = cleaned_input.select_dtypes(['object']).drop(['Customer'], axis=1)\n",
    "    \n",
    "    # Define target and features\n",
    "y = cleaned_input['Total Claim Amount']\n",
    "X = numericals.drop(['Total Claim Amount', 'Income', 'Months Since Last Claim', 'Months Since Policy Inception', 'Number of Open Complaints', 'Number of Policies'], axis = 1)\n",
    "    \n",
    "    # Standardize the features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "transformer = StandardScaler().fit(X)\n",
    "X_standardized = transformer.transform(X)\n",
    "X_standardized = pd.DataFrame(X_standardized, columns=X.columns)\n",
    "    \n",
    "    # Standardize the categoricals\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "cat_onehot = categoricals[['State', 'Response', 'Employment Status', 'Gender', 'Location Code', 'Marital Status', 'Policy Type', 'Policy', 'Sales Channel', 'Vehicle Class']].copy()\n",
    "encoder = OneHotEncoder().fit(cat_onehot)\n",
    "cols = [colname for row in encoder.categories_ for colname in row]\n",
    "encoded = encoder.transform(cat_onehot).toarray()\n",
    "cat_onehot_encoded = pd.DataFrame(encoded,columns=cols)\n",
    "cols_to_drop = [row[0] for row in encoder.categories_]\n",
    "cat_onehot_encoded = cat_onehot_encoded.drop(cols_to_drop, axis=1)\n",
    "    \n",
    "cat_label = categoricals[['Coverage', 'Renew Offer Type', 'Education', 'Vehicle Size']].copy()\n",
    "coverage_mapper = { 'Basic':1, 'Extended':2, 'Premium':3 }\n",
    "education_mapper = { 'High School or Below':1, 'College':2, 'Bachelor':3, 'Master':4, 'Doctor':5 }\n",
    "veh_size_mapper = { 'Small':1, 'Medsize':2, 'Large':3 }\n",
    "\n",
    "cat_label['Coverage'] = cat_label['Coverage'].replace(coverage_mapper)\n",
    "cat_label['Education'] = cat_label['Education'].replace(education_mapper)\n",
    "cat_label['Vehicle Size'] = cat_label['Vehicle Size'].replace(veh_size_mapper)\n",
    "cat_label['Renew Offer Type'] = cat_label['Renew Offer Type'].str[-1:]\n",
    "cat_label.reset_index(drop=True, inplace=True)    # used to reset the index, as the concatenate below was generating more rows than the input df had\n",
    "cat_onehot_encoded.reset_index(drop=True, inplace=True)    # used to reset the index, as the concatenate below was generating more rows than the input df had\n",
    "categoricals_encoded = pd.concat([cat_onehot_encoded, cat_label], axis=1)\n",
    "X_complete = pd.concat([X_standardized, categoricals_encoded], axis=1)\n",
    "\n",
    "    # Linear regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_complete, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "from sklearn import linear_model\n",
    "lm = linear_model.LinearRegression()\n",
    "lm.fit(X_train,y_train)\n",
    "    \n",
    "    \n",
    "from sklearn.metrics import r2_score\n",
    "predictions_train = lm.predict(X_train)\n",
    "R2_train = r2_score(y_train, predictions_train)\n",
    "predictions_test = lm.predict(X_test)\n",
    "R2_test = r2_score(y_test, predictions_test)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse_train = np.sqrt(mean_squared_error(y_train,predictions_train))\n",
    "mse_test = np.sqrt(mean_squared_error(y_test,predictions_test))\n",
    "    \n",
    "import math\n",
    "rmse_train = math.sqrt(mse_train)\n",
    "rmse_test = math.sqrt(mse_test)\n",
    "    \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae_train = mean_absolute_error(y_train, predictions_train)\n",
    "mae_test = mean_absolute_error(y_test, predictions_test)\n",
    "    \n",
    "# Creation of a dataframe as ouput (based on example found there : https://www.geeksforgeeks.org/different-ways-to-create-pandas-dataframe/)\n",
    "    \n",
    "validation_matrix = { 'Train Set': [R2_train, mse_train, rmse_train, mae_train],\n",
    "                 'Test Set': [R2_test, mse_test, rmse_test, mae_test]\n",
    "                } \n",
    "validation_matrix = pd.DataFrame(validation_matrix, index=['R2','mse', 'rmse', 'mae'])\n",
    "    \n",
    "# return validation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddaa829",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23df1b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3949.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data['Number of Open Complaints'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9adbc00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2e711c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(input_data['Number of Open Complaints'], 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6992e477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b039525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1023c53c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b286c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a0b07b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f54c846",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2020d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e753901b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f07ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c29282a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53ccf88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca695b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18574146",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f35290d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b1f642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc9f0e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540d5e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df3f5db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a2a893",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af6167c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57106518",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8ada1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71856428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2c2f3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Set</th>\n",
       "      <th>Test Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>0.742529</td>\n",
       "      <td>0.758946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mse</th>\n",
       "      <td>117.292850</td>\n",
       "      <td>115.429813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>10.830182</td>\n",
       "      <td>10.743827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mae</th>\n",
       "      <td>84.339130</td>\n",
       "      <td>84.017166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Train Set    Test Set\n",
       "R2      0.742529    0.758946\n",
       "mse   117.292850  115.429813\n",
       "rmse   10.830182   10.743827\n",
       "mae    84.339130   84.017166"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a39f67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
